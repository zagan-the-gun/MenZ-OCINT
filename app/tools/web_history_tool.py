import json
import requests
from datetime import datetime, timezone
from typing import Dict, List, Any, Optional
import traceback

def web_history_lookup(domain: str, query_type: str = "COMPREHENSIVE") -> str:
    """
    Webå±¥æ­´èª¿æŸ»ã‚’å®Ÿè¡Œã™ã‚‹é–¢æ•°
    
    Args:
        domain: èª¿æŸ»å¯¾è±¡ã®ãƒ‰ãƒ¡ã‚¤ãƒ³
        query_type: èª¿æŸ»ã‚¿ã‚¤ãƒ— (COMPREHENSIVE, WEB_ARCHIVE, CERT_ANALYSIS, TECH_ANALYSIS, DOMAIN_TIMELINE)
    
    Returns:
        èª¿æŸ»çµæœã®æ–‡å­—åˆ—
    """
    try:
        domain = domain.strip().lower()
        
        # ãƒ‰ãƒ¡ã‚¤ãƒ³ã®åŸºæœ¬çš„ãªæ¤œè¨¼
        if not domain or '.' not in domain:
            return f"ã‚¨ãƒ©ãƒ¼: ç„¡åŠ¹ãªãƒ‰ãƒ¡ã‚¤ãƒ³åã§ã™: {domain}"
        
        if query_type == "COMPREHENSIVE":
            return _comprehensive_analysis(domain)
        elif query_type == "WEB_ARCHIVE":
            return _web_archive_analysis(domain)
        elif query_type == "CERT_ANALYSIS":
            return _certificate_analysis(domain)
        elif query_type == "TECH_ANALYSIS":
            return _technical_analysis(domain)
        elif query_type == "DOMAIN_TIMELINE":
            return _domain_timeline(domain)
        else:
            return f"ã‚¨ãƒ©ãƒ¼: ä¸æ˜ãªèª¿æŸ»ã‚¿ã‚¤ãƒ—ã§ã™: {query_type}"
            
    except Exception as e:
        return f"Webå±¥æ­´èª¿æŸ»ã‚¨ãƒ©ãƒ¼: {str(e)}\n{traceback.format_exc()}"

def _comprehensive_analysis(domain: str) -> str:
    """åŒ…æ‹¬çš„ãªåˆ†æã‚’å®Ÿè¡Œ"""
    result = f"=== {domain} åŒ…æ‹¬çš„Webå±¥æ­´èª¿æŸ» ===\n\n"
    
    # Certificate Transparencyåˆ†æ
    result += "ğŸ” Certificate Transparencyåˆ†æ\n"
    result += "=" * 50 + "\n"
    cert_data = _get_certificate_data(domain)
    if cert_data:
        result += _format_certificate_analysis(cert_data)
    else:
        result += "è¨¼æ˜æ›¸ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ\n"
    result += "\n"
    
    # Wayback Machineåˆ†æ
    result += "ğŸŒ Wayback Machineå±¥æ­´åˆ†æ\n"
    result += "=" * 50 + "\n"
    archive_data = _get_wayback_data(domain)
    if archive_data:
        result += _format_wayback_analysis(archive_data)
    else:
        result += "ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ\n"
    result += "\n"
    
    # æŠ€è¡“çš„åˆ†æ
    result += "ğŸ› ï¸ æŠ€è¡“ã‚¤ãƒ³ãƒ•ãƒ©åˆ†æ\n"
    result += "=" * 50 + "\n"
    if cert_data:
        result += _format_technical_analysis(cert_data)
    else:
        result += "æŠ€è¡“åˆ†æã«å¿…è¦ãªãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã¾ã™\n"
    result += "\n"
    
    # ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³åˆ†æ
    result += "ğŸ“… æ´»å‹•ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³\n"
    result += "=" * 50 + "\n"
    result += _format_timeline_analysis(cert_data, archive_data)
    
    return result

def _web_archive_analysis(domain: str) -> str:
    """Wayback Machineå°‚ç”¨åˆ†æ"""
    result = f"=== {domain} Wayback Machineå±¥æ­´èª¿æŸ» ===\n\n"
    
    # ãƒ¡ã‚¤ãƒ³ãƒ‰ãƒ¡ã‚¤ãƒ³ã¨wwwã‚µãƒ–ãƒ‰ãƒ¡ã‚¤ãƒ³ã®ä¸¡æ–¹ã‚’èª¿æŸ»
    domains_to_check = [domain, f"www.{domain}"]
    
    for check_domain in domains_to_check:
        result += f"ğŸ“‹ {check_domain} ã®ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–å±¥æ­´\n"
        result += "-" * 40 + "\n"
        
        archive_data = _get_wayback_data(check_domain)
        if archive_data:
            result += _format_wayback_analysis(archive_data)
        else:
            result += f"{check_domain} ã®ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ\n"
        result += "\n"
    
    return result

def _certificate_analysis(domain: str) -> str:
    """Certificate Transparencyå°‚ç”¨åˆ†æ"""
    result = f"=== {domain} Certificate Transparencyåˆ†æ ===\n\n"
    
    cert_data = _get_certificate_data(domain)
    if cert_data:
        result += _format_certificate_analysis(cert_data)
        result += "\n"
        result += _format_technical_analysis(cert_data)
    else:
        result += "è¨¼æ˜æ›¸ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ\n"
    
    return result

def _technical_analysis(domain: str) -> str:
    """æŠ€è¡“ã‚¤ãƒ³ãƒ•ãƒ©å°‚ç”¨åˆ†æ"""
    result = f"=== {domain} æŠ€è¡“ã‚¤ãƒ³ãƒ•ãƒ©åˆ†æ ===\n\n"
    
    cert_data = _get_certificate_data(domain)
    if cert_data:
        result += _format_technical_analysis(cert_data)
    else:
        result += "æŠ€è¡“åˆ†æã«å¿…è¦ãªãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã¾ã™\n"
    
    return result

def _domain_timeline(domain: str) -> str:
    """ãƒ‰ãƒ¡ã‚¤ãƒ³ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³å°‚ç”¨åˆ†æ"""
    result = f"=== {domain} ãƒ‰ãƒ¡ã‚¤ãƒ³ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³ ===\n\n"
    
    cert_data = _get_certificate_data(domain)
    archive_data = _get_wayback_data(domain)
    
    result += _format_timeline_analysis(cert_data, archive_data)
    
    return result

def _get_certificate_data(domain: str) -> Optional[List[Dict]]:
    """Certificate Transparencyãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—"""
    try:
        url = f'https://crt.sh/?q={domain}&output=json'
        response = requests.get(url, timeout=10)
        
        if response.status_code == 200:
            data = response.json()
            if isinstance(data, list) and len(data) > 0:
                return data
    except Exception as e:
        print(f"Certificate Transparencyå–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
    
    return None

def _get_wayback_data(domain: str) -> Optional[List[List]]:
    """Wayback Machineãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—"""
    try:
        url = f'https://web.archive.org/cdx/search/cdx?url={domain}&output=json&limit=50'
        response = requests.get(url, timeout=10)
        
        if response.status_code == 200:
            data = response.json()
            if isinstance(data, list) and len(data) > 1:  # ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œã‚’é™¤ã
                return data
    except Exception as e:
        print(f"Wayback Machineå–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
    
    return None

def _format_certificate_analysis(cert_data: List[Dict]) -> str:
    """è¨¼æ˜æ›¸åˆ†æçµæœã‚’ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ"""
    result = f"ç·è¨¼æ˜æ›¸æ•°: {len(cert_data)}ä»¶\n\n"
    
    # è¨¼æ˜æ›¸ã‚’æ—¥ä»˜é †ã«ã‚½ãƒ¼ãƒˆ
    sorted_certs = sorted(cert_data, key=lambda x: x.get('not_before', ''))
    
    # æœ€åˆã¨æœ€å¾Œã®è¨¼æ˜æ›¸
    if sorted_certs:
        first_cert = sorted_certs[0]
        last_cert = sorted_certs[-1]
        
        result += "ğŸ” è¨¼æ˜æ›¸ã®ä½¿ç”¨æœŸé–“\n"
        result += f"  æœ€åˆã®è¨¼æ˜æ›¸: {first_cert.get('not_before', 'N/A')}\n"
        result += f"  æœ€æ–°ã®è¨¼æ˜æ›¸: {last_cert.get('not_before', 'N/A')}\n"
        result += f"  æœ€æ–°ã®æœ‰åŠ¹æœŸé™: {last_cert.get('not_after', 'N/A')}\n\n"
    
    # è¨¼æ˜æ›¸ç™ºè¡Œè€…ã®åˆ†æ
    issuers = {}
    for cert in cert_data:
        issuer = cert.get('issuer_name', 'Unknown')
        issuers[issuer] = issuers.get(issuer, 0) + 1
    
    result += "ğŸ” è¨¼æ˜æ›¸ç™ºè¡Œè€…ã®åˆ†æ\n"
    for issuer, count in sorted(issuers.items(), key=lambda x: x[1], reverse=True):
        result += f"  {issuer}: {count}ä»¶\n"
    result += "\n"
    
    # å¹´åˆ¥ã®è¨¼æ˜æ›¸ç™ºè¡Œæ•°
    years = {}
    for cert in cert_data:
        date_str = cert.get('not_before', '')
        if date_str:
            try:
                year = date_str[:4]
                years[year] = years.get(year, 0) + 1
            except:
                pass
    
    result += "ğŸ” å¹´åˆ¥è¨¼æ˜æ›¸ç™ºè¡Œæ•°\n"
    for year, count in sorted(years.items()):
        result += f"  {year}å¹´: {count}ä»¶\n"
    result += "\n"
    
    # ã‚µãƒ–ãƒ‰ãƒ¡ã‚¤ãƒ³ã®ç¢ºèª
    subdomains = set()
    for cert in cert_data:
        common_name = cert.get('common_name', '')
        name_value = cert.get('name_value', '')
        if common_name:
            subdomains.add(common_name)
        if name_value:
            for name in name_value.split('\n'):
                if name.strip():
                    subdomains.add(name.strip())
    
    result += "ğŸ” ç™ºè¦‹ã•ã‚ŒãŸã‚µãƒ–ãƒ‰ãƒ¡ã‚¤ãƒ³\n"
    for subdomain in sorted(subdomains):
        result += f"  {subdomain}\n"
    result += "\n"
    
    return result

def _format_wayback_analysis(archive_data: List[List]) -> str:
    """Wayback Machineåˆ†æçµæœã‚’ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ"""
    archives = archive_data[1:]  # ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œã‚’é™¤ã
    result = f"ç·ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–æ•°: {len(archives)}ä»¶\n\n"
    
    if archives:
        # æœ€åˆã¨æœ€å¾Œã®ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–
        first_archive = archives[0]
        last_archive = archives[-1]
        
        result += "ğŸ” ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ã®æœŸé–“\n"
        result += f"  æœ€åˆã®ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–: {first_archive[1]} - {first_archive[2]}\n"
        result += f"  æœ€å¾Œã®ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–: {last_archive[1]} - {last_archive[2]}\n\n"
        
        # å¹´åˆ¥ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–æ•°
        years = {}
        for archive in archives:
            year = archive[1][:4]
            years[year] = years.get(year, 0) + 1
        
        result += "ğŸ” å¹´åˆ¥ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–æ•°\n"
        for year, count in sorted(years.items()):
            result += f"  {year}å¹´: {count}ä»¶\n"
        result += "\n"
        
        # HTTPã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚³ãƒ¼ãƒ‰åˆ†æ
        status_codes = {}
        for archive in archives:
            if len(archive) > 4:
                status = archive[4]
                status_codes[status] = status_codes.get(status, 0) + 1
        
        result += "ğŸ” HTTPã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚³ãƒ¼ãƒ‰åˆ†å¸ƒ\n"
        for status, count in sorted(status_codes.items()):
            result += f"  {status}: {count}ä»¶\n"
        result += "\n"
        
        # æœ€è¿‘ã®ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–è©³ç´°
        result += "ğŸ” æœ€è¿‘ã®ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–è©³ç´°\n"
        for archive in archives[-5:]:
            timestamp = archive[1]
            url = archive[2]
            status = archive[4] if len(archive) > 4 else 'N/A'
            mimetype = archive[3] if len(archive) > 3 else 'N/A'
            result += f"  {timestamp}: {url} (Status: {status}, Type: {mimetype})\n"
        result += "\n"
    
    return result

def _format_technical_analysis(cert_data: List[Dict]) -> str:
    """æŠ€è¡“åˆ†æçµæœã‚’ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ"""
    result = ""
    
    # Cloudflareã®ä½¿ç”¨å±¥æ­´åˆ†æ
    cloudflare_certs = [cert for cert in cert_data if 'cloudflare' in cert.get('issuer_name', '').lower()]
    
    if cloudflare_certs:
        result += "ğŸ” Cloudflareã®ä½¿ç”¨å±¥æ­´\n"
        result += f"  Cloudflareè¨¼æ˜æ›¸: {len(cloudflare_certs)}ä»¶\n"
        for cert in cloudflare_certs:
            result += f"  ç™ºè¡ŒæœŸé–“: {cert.get('not_before', 'N/A')} ï½ {cert.get('not_after', 'N/A')}\n"
        result += "\n"
    
    # è¨¼æ˜æ›¸æ›´æ–°ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ
    sorted_certs = sorted(cert_data, key=lambda x: x.get('not_before', ''))
    renewal_intervals = []
    
    for i in range(1, len(sorted_certs)):
        try:
            prev_date = datetime.fromisoformat(sorted_certs[i-1].get('not_before', '').replace('Z', '+00:00'))
            curr_date = datetime.fromisoformat(sorted_certs[i].get('not_before', '').replace('Z', '+00:00'))
            interval = (curr_date - prev_date).days
            if 0 < interval < 365:  # 1å¹´ä»¥å†…ã®æ›´æ–°
                renewal_intervals.append(interval)
        except:
            pass
    
    if renewal_intervals:
        avg_interval = sum(renewal_intervals) / len(renewal_intervals)
        result += "ğŸ” è¨¼æ˜æ›¸æ›´æ–°ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ\n"
        result += f"  å¹³å‡æ›´æ–°é–“éš”: {avg_interval:.1f}æ—¥\n"
        result += f"  æœ€çŸ­æ›´æ–°é–“éš”: {min(renewal_intervals)}æ—¥\n"
        result += f"  æœ€é•·æ›´æ–°é–“éš”: {max(renewal_intervals)}æ—¥\n"
        
        # æ›´æ–°é »åº¦ã®åˆ†æ
        if avg_interval < 30:
            result += "  ğŸ”¸ é »ç¹ãªè¨¼æ˜æ›¸æ›´æ–° - è‡ªå‹•æ›´æ–°ã‚·ã‚¹ãƒ†ãƒ ä½¿ç”¨ã®å¯èƒ½æ€§\n"
        elif avg_interval < 90:
            result += "  ğŸ”¸ å®šæœŸçš„ãªè¨¼æ˜æ›¸æ›´æ–° - 90æ—¥ã‚µã‚¤ã‚¯ãƒ«ï¼ˆLet's Encryptæ¨™æº–ï¼‰\n"
        else:
            result += "  ğŸ”¸ é•·æœŸé–“ã®è¨¼æ˜æ›¸æ›´æ–° - æœ‰æ–™è¨¼æ˜æ›¸ä½¿ç”¨ã®å¯èƒ½æ€§\n"
        result += "\n"
    
    # è¨¼æ˜æ›¸ã®ç¨®é¡åˆ†æ
    cert_types = {'DV': 0, 'OV': 0, 'EV': 0, 'Wildcard': 0}
    
    for cert in cert_data:
        common_name = cert.get('common_name', '')
        name_value = cert.get('name_value', '')
        
        if common_name.startswith('*.') or '*.artoautio.com' in name_value:
            cert_types['Wildcard'] += 1
        else:
            cert_types['DV'] += 1  # åŸºæœ¬çš„ã«ã¯DVè¨¼æ˜æ›¸
    
    result += "ğŸ” è¨¼æ˜æ›¸ç¨®é¡ã®åˆ†å¸ƒ\n"
    for cert_type, count in cert_types.items():
        if count > 0:
            result += f"  {cert_type}: {count}ä»¶\n"
    result += "\n"
    
    # æ´»å‹•åœæ­¢æ™‚æœŸã®æ¨å®š
    if sorted_certs:
        latest_cert = sorted_certs[-1]
        latest_date = latest_cert.get('not_before', '')
        expiry_date = latest_cert.get('not_after', '')
        
        result += "ğŸ” æ´»å‹•åœæ­¢æ™‚æœŸã®æ¨å®š\n"
        result += f"  æœ€æ–°ã®è¨¼æ˜æ›¸ç™ºè¡Œ: {latest_date}\n"
        result += f"  æœ€æ–°ã®è¨¼æ˜æ›¸æœ‰åŠ¹æœŸé™: {expiry_date}\n"
        
        try:
            expiry_dt = datetime.fromisoformat(expiry_date.replace('Z', '+00:00'))
            now = datetime.now(timezone.utc)
            if now > expiry_dt:
                result += "  ğŸ”´ è¨¼æ˜æ›¸ã¯æ—¢ã«æœŸé™åˆ‡ã‚Œ - ã‚µã‚¤ãƒˆã¯åœæ­¢ã—ã¦ã„ã‚‹å¯èƒ½æ€§ãŒé«˜ã„\n"
            else:
                days_remaining = (expiry_dt - now).days
                result += f"  ğŸŸ¡ è¨¼æ˜æ›¸æœ‰åŠ¹æœŸé™ã¾ã§æ®‹ã‚Š {days_remaining} æ—¥\n"
        except:
            result += "  ğŸ”´ è¨¼æ˜æ›¸æœŸé™ã®ç¢ºèªã«å¤±æ•—\n"
        result += "\n"
    
    return result

def _format_timeline_analysis(cert_data: Optional[List[Dict]], archive_data: Optional[List[List]]) -> str:
    """ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³åˆ†æçµæœã‚’ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ"""
    result = ""
    
    # è¨¼æ˜æ›¸ã¨ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ã®çµ±åˆã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³
    events = []
    
    if cert_data:
        for cert in cert_data:
            date_str = cert.get('not_before', '')
            if date_str:
                try:
                    date = datetime.fromisoformat(date_str.replace('Z', '+00:00'))
                    issuer = cert.get('issuer_name', 'Unknown')[:50]  # é•·ã™ãã‚‹å ´åˆã¯åˆ‡ã‚Šè©°ã‚
                    events.append((date, 'CERT', f"è¨¼æ˜æ›¸ç™ºè¡Œ: {issuer}"))
                except:
                    pass
    
    if archive_data:
        archives = archive_data[1:]  # ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œã‚’é™¤ã
        for archive in archives:
            timestamp = archive[1]
            try:
                date = datetime.strptime(timestamp, '%Y%m%d%H%M%S').replace(tzinfo=timezone.utc)
                url = archive[2]
                status = archive[4] if len(archive) > 4 else 'N/A'
                events.append((date, 'ARCHIVE', f"ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–: {url} (Status: {status})"))
            except:
                pass
    
    # ã‚¤ãƒ™ãƒ³ãƒˆã‚’æ™‚ç³»åˆ—é †ã«ã‚½ãƒ¼ãƒˆ
    events.sort(key=lambda x: x[0])
    
    if events:
        result += "ğŸ“… æ™‚ç³»åˆ—ã‚¤ãƒ™ãƒ³ãƒˆï¼ˆæœ€æ–°20ä»¶ï¼‰\n"
        for date, event_type, description in events[-20:]:
            result += f"  {date.strftime('%Y-%m-%d %H:%M:%S')} [{event_type}] {description}\n"
        result += "\n"
        
        # æ´»å‹•æœŸé–“ã®åˆ†æ
        if len(events) > 1:
            start_date = events[0][0]
            end_date = events[-1][0]
            duration = (end_date - start_date).days
            
            result += "ğŸ” æ´»å‹•æœŸé–“ã®åˆ†æ\n"
            result += f"  é–‹å§‹æ—¥: {start_date.strftime('%Y-%m-%d')}\n"
            result += f"  æœ€çµ‚æ´»å‹•æ—¥: {end_date.strftime('%Y-%m-%d')}\n"
            result += f"  ç·æ´»å‹•æœŸé–“: {duration}æ—¥ï¼ˆç´„{duration//365}å¹´{(duration%365)//30}ãƒ¶æœˆï¼‰\n"
    else:
        result += "ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³åˆ†æã«å¿…è¦ãªãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã¾ã™\n"
    
    return result

def web_history_wrapper(query: str) -> str:
    """
    Webå±¥æ­´èª¿æŸ»ã®ãƒ©ãƒƒãƒ‘ãƒ¼é–¢æ•°
    
    Args:
        query: "domain_name QUERY_TYPE" å½¢å¼ã®æ–‡å­—åˆ—
               ä¾‹: "example.com COMPREHENSIVE", "example.com WEB_ARCHIVE"
    
    Returns:
        èª¿æŸ»çµæœã®æ–‡å­—åˆ—
    """
    try:
        parts = query.strip().split()
        if len(parts) < 1:
            return "ã‚¨ãƒ©ãƒ¼: ãƒ‰ãƒ¡ã‚¤ãƒ³åã‚’æŒ‡å®šã—ã¦ãã ã•ã„"
        
        domain = parts[0]
        query_type = parts[1] if len(parts) > 1 else "COMPREHENSIVE"
        
        return web_history_lookup(domain, query_type)
        
    except Exception as e:
        return f"Webå±¥æ­´èª¿æŸ»ã‚¨ãƒ©ãƒ¼: {str(e)}"

# LangChain Tool definition
from langchain.tools import Tool

web_history_tool = Tool(
    name="web_history_lookup",
    description=(
        "Webå±¥æ­´èª¿æŸ»ãƒ„ãƒ¼ãƒ«ã€‚Certificate Transparencyã¨Wayback Machineã‚’ä½¿ç”¨ã—ã¦ãƒ‰ãƒ¡ã‚¤ãƒ³ã®åŒ…æ‹¬çš„ãªå±¥æ­´ã‚’èª¿æŸ»ã—ã¾ã™ã€‚"
        "ä½¿ç”¨æ–¹æ³•: 'domain_name QUERY_TYPE'ã®å½¢å¼ã§å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚"
        "QUERY_TYPEã¯ä»¥ä¸‹ã‹ã‚‰é¸æŠ: "
        "COMPREHENSIVEï¼ˆåŒ…æ‹¬çš„ãªåˆ†æï¼‰, WEB_ARCHIVEï¼ˆWayback Machineå±¥æ­´ï¼‰, CERT_ANALYSISï¼ˆè¨¼æ˜æ›¸åˆ†æï¼‰, "
        "TECH_ANALYSISï¼ˆæŠ€è¡“ã‚¤ãƒ³ãƒ•ãƒ©åˆ†æï¼‰, DOMAIN_TIMELINEï¼ˆãƒ‰ãƒ¡ã‚¤ãƒ³ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³ï¼‰ã€‚"
        "çœç•¥ã—ãŸå ´åˆã¯COMPREHENSIVEãŒä½¿ç”¨ã•ã‚Œã¾ã™ã€‚"
        "ä¾‹: 'example.com COMPREHENSIVE', 'example.com WEB_ARCHIVE'"
    ),
    func=web_history_wrapper
) 